{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "#default_exp export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nbdev.export\n",
    "- Exporting a notebook to a library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from nbdev.read import *\n",
    "\n",
    "from nbdev.imports import *\n",
    "from fastcore.script import *\n",
    "from fastcore.imports import *\n",
    "\n",
    "from collections import defaultdict\n",
    "from pprint import pformat\n",
    "import ast,contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastcore.test import *\n",
    "from pdb import set_trace\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NotebookProcessor -"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Special comments at the start of a cell can be used to provide information to `nbdev` about how to process a cell, so we need to be able to find the location of these comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimal = read_nb('../tests/minimal.ipynb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def extract_comments(ss):\n",
    "    \"Take leading comments from lines of code in `ss`, remove `#`, and split\"\n",
    "    ss = ss.splitlines()\n",
    "    first_code = first(i for i,o in enumerate(ss) if not o.strip() or re.match('\\s*[^#\\s]', o)) or 0\n",
    "    return L((s.strip()[1:]).strip().split() for s in ss[:first_code]).filter()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nbdev comments start with `#`, followed by whitespace delimited tokens, which `extract_comments` extracts from the start of a cell, up until a blank line or a line containing something other than comments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp  = \"#export module\\n# hide\\n1+2\\n#foo\\n#bar\"\n",
    "test_eq(extract_comments(exp), [['export', 'module'],['hide']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NotebookProcessor:\n",
    "    \"Base class for nbdev notebook processors\"\n",
    "    def __init__(self, path, debug=False): self.nb,self.path,self.debug = read_nb(path),Path(path),debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subclass `NotebookProcessor` to add methods to act on nbdev comments. The method names are of the form `cmd_type`, where \"`cmd`\" is the first word of the nbdev comment, and `type` is the `cell_type` of the cell (normally \"`code`). The methods must take at least `comment` and `code` as params, plus extra params for any additional words included in a comment. Here's an example that prints any word following a \"print me\" comment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _PrintExample(NotebookProcessor):\n",
    "    def printme_code(self, comment, code, to_print): print(to_print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a processor by passing it a notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything_fn = '../tests/01_everything.ipynb'\n",
    "proc = _PrintExample(everything_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic functionality of a notebook processor is to read and act on nbdev comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def process_comment(self:NotebookProcessor, comment, cell):\n",
    "    cmd,*args = comment\n",
    "    cmd = f\"{cmd}_{cell.cell_type}\"\n",
    "    if self.debug: print(cmd, args)\n",
    "    if not hasattr(self, cmd): return\n",
    "    try: getattr(self,cmd)(comment,cell, *args)\n",
    "    except TypeError: pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, `process_comment`  is used to call subclass methods. You can subclass this to change the behavior of a processor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "proc.process_comment([\"printme\",\"hello\"], SimpleNamespace(cell_type=\"code\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def process_cell(self:NotebookProcessor, cell):\n",
    "    comments = extract_comments(cell.source)\n",
    "    if not comments: return self.no_cmd(cell)\n",
    "    for comment in comments: self.process_comment(comment, cell)\n",
    "    return cell\n",
    "\n",
    "@patch\n",
    "def no_cmd(self:NotebookProcessor, cell): return cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subclass `process_cell` to change how `process_comment` is called. By default, it calls `self.no_cmd` for any cells without comments. The return value of `process_cell` is used to replace the cell in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _make_code_cell(code, idx=0): return AttrDict(source=code, cell_type=\"code\")\n",
    "def _make_code_cells(*ss): return dict2nb({'cells':L(ss).map(_make_code_cell)}).cells\n",
    "\n",
    "proc.process_cell(_make_code_cell(\"#printme hello\"));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def process(self:NotebookProcessor):\n",
    "    \"Process all cells with `process_cell` and replace `self.nb.cells` with result\"\n",
    "    for i in range_of(self.nb.cells): self.nb.cells[i] = self.process_cell(self.nb.cells[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing\n"
     ]
    }
   ],
   "source": [
    "proc.process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`NotebookProcessor.process` doesn't change a notebook or act on any comments, unless you subclass it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "everything = read_nb(everything_fn)\n",
    "proc = NotebookProcessor(everything_fn)\n",
    "proc.process()\n",
    "for a_,b_ in zip(everything.cells, proc.nb.cells): test_eq(str(a_),str(b_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable helpers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions let us find and modify the definitions of variables in python modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def find_var(lines, varname):\n",
    "    \"Find the line numbers where `varname` is defined in `lines`\"\n",
    "    start = first(i for i,o in enumerate(lines) if o.startswith(varname))\n",
    "    if start is None: return None,None\n",
    "    empty = ' ','\\t'\n",
    "    if start==len(lines)-1 or lines[start+1][:1] not in empty: return start,start+1\n",
    "    end = first(i for i,o in enumerate(lines[start+1:]) if o[:1] not in empty)\n",
    "    return start,len(lines) if end is None else (end+start+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 'a_=(1,\\n  2,\\n  3)\\n\\nb_=3'\n",
    "test_eq(find_var(t.splitlines(), 'a_'), (0,3))\n",
    "test_eq(find_var(t.splitlines(), 'b_'), (4,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def read_var(code, varname):\n",
    "    \"Eval and return the value of `varname` defined in `code`\"\n",
    "    lines = code.splitlines()\n",
    "    start,end = find_var(lines, varname)\n",
    "    if start is None: return None\n",
    "    res = [lines[start].split('=')[-1].strip()]\n",
    "    res += lines[start+1:end]\n",
    "    try: return eval('\\n'.join(res))\n",
    "    except SyntaxError: raise Exception('\\n'.join(res)) from None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(read_var(t, 'a_'), (1,2,3))\n",
    "test_eq(read_var(t, 'b_'), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_var(varname, func, fn=None, code=None):\n",
    "    \"Update the definition of `varname` in file `fn`, by calling `func` with the current definition\"\n",
    "    if fn:\n",
    "        fn = Path(fn)\n",
    "        code = fn.read_text()\n",
    "    lines = code.splitlines()\n",
    "    v = read_var(code, varname)\n",
    "    res = func(v)\n",
    "    start,end = find_var(lines, varname)\n",
    "    del(lines[start:end])\n",
    "    lines.insert(start, f\"{varname} = {res}\")\n",
    "    code = '\\n'.join(lines)\n",
    "    if fn: fn.write_text(code)\n",
    "    else: return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exec(t)\n",
    "test_eq((a_,b_), ((1,2,3),3))\n",
    "t2 = update_var('a_', lambda o:0, code=t)\n",
    "exec(t2)\n",
    "test_eq((a_,b_), (0,3))\n",
    "t3 = update_var('b_', lambda o:0, code=t)\n",
    "exec(t3)\n",
    "test_eq((a_,b_), ((1,2,3),0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ModuleMaker -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ModuleMaker:\n",
    "    \"Helper class to create exported library from notebook source cells\"\n",
    "    def __init__(self, dest, name, nb_path, is_new=True):\n",
    "        dest,nb_path = Path(dest),Path(nb_path)\n",
    "        store_attr()\n",
    "        self.fname = dest/(name.replace('.','/') + \".py\")\n",
    "        if is_new: dest.mkdir(parents=True, exist_ok=True)\n",
    "        else: assert self.fname.exists(), f\"{self.fname} does not exist\"\n",
    "        self.dest2nb = nb_path.relpath(dest)\n",
    "#         relp = nb_path.relpath(get_config().path('lib_path'))\n",
    "        self.hdr = f\"# %% {self.dest2nb}\"\n",
    "        print(self.hdr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/jhoward/git/nbdev/nbdev')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_config().path('lib_path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to export a notebook, we need an way to create a Python file. `ModuleMaker` fills that role. Pass in the directory where you want to module created, the name of the module, the path of the notebook source, and set `is_new` to `True` if this is a new file being created (rather than an existing file being added to). The location of the saved module will be in `fname`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# %% ../01_export.ipynb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Path('tmp/test/testing.py')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mm = ModuleMaker(dest='tmp', name='test.testing', nb_path=Path.cwd()/'01_export.ipynb', is_new=True)\n",
    "mm.fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "_def_types = ast.FunctionDef,ast.AsyncFunctionDef,ast.ClassDef\n",
    "_assign_types = ast.AnnAssign, ast.Assign, ast.AugAssign\n",
    "\n",
    "def _val_or_id(it): return [getattr(o, 'value', getattr(o, 'id', None)) for o in it.value.elts]\n",
    "def _all_targets(a): return L(getattr(a,'elts',a))\n",
    "def _wants(o): return isinstance(o,_def_types) and not any(L(o.decorator_list).filter(Self.id.startswith('patch')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def retr_exports(trees):\n",
    "    # include anything mentioned in \"_all_\", even if otherwise private\n",
    "    # NB: \"_all_\" can include strings (names), or symbols, so we look for \"id\" or \"value\"\n",
    "    assigns = trees.filter(risinstance(_assign_types))\n",
    "    all_assigns = assigns.filter(lambda o: getattr(o.targets[0],'id',None)=='_all_')\n",
    "    all_vals = all_assigns.map(_val_or_id).concat()\n",
    "    syms = trees.filter(_wants).attrgot('name')\n",
    "\n",
    "    # assignment targets (NB: can be multiple, e.g. \"a=b=c\", and/or destructuring e.g \"a,b=(1,2)\")\n",
    "    assign_targs = L(L(assn.targets).map(_all_targets).concat() for assn in assigns).concat()\n",
    "    exports = (assign_targs.attrgot('id')+syms).filter(lambda o: o and o[0]!='_')\n",
    "    return (exports+all_vals).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def make_all(self:ModuleMaker, cells):\n",
    "    \"Create `__all__` with all exports in `cells`\"\n",
    "    if cells is None: return ''\n",
    "    parsed = cells.attrgot('parsed').concat()\n",
    "    return retr_exports(parsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to add an `__all__` to the top of the exported module. This methods autogenerates it from all code in `cells`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = _make_code_cells(\"from __future__ import print_function\", \"def a():...\", \"def b():...\",\n",
    "                      \"c=d=1\", \"_f=1\", \"_g=1\", \"_all_=['_g']\", \"@patch\\ndef h(self:ca):...\")\n",
    "test_eq(set(mm.make_all(nb)), set(['a','b','c','d', '_g']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def relative_import(name, fname, level=0):\n",
    "    \"Convert a module `name` to a name relative to `fname`\"\n",
    "    assert not level\n",
    "    sname = name.replace('.','/')\n",
    "    if not(os.path.commonpath([sname,fname])): return name\n",
    "    rel = os.path.relpath(sname, fname)\n",
    "    if rel==\".\": return \".\"\n",
    "    res = rel.replace(f\"..{os.path.sep}\", \".\")\n",
    "    return \".\" + res.replace(os.path.sep, \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(relative_import('nbdev.core', \"xyz\"), 'nbdev.core')\n",
    "test_eq(relative_import('nbdev.core', 'nbdev'), '.core')\n",
    "_p = Path('fastai')\n",
    "test_eq(relative_import('fastai.core', _p/'vision'), '..core')\n",
    "test_eq(relative_import('fastai.core', _p/'vision/transform'), '...core')\n",
    "test_eq(relative_import('fastai.vision.transform', _p/'vision'), '.transform')\n",
    "test_eq(relative_import('fastai.notebook.core', _p/'data'), '..notebook.core')\n",
    "test_eq(relative_import('fastai.vision', _p/'vision'), '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def absolute_import(name, fname, level):\n",
    "    \"Unwarps a relative import in `name` according to `mod_name`\"\n",
    "    if not level: return name\n",
    "    mods = fname.split(os.path.sep)\n",
    "    if not name: return '.'.join(mods)\n",
    "    return '.'.join(mods[:len(mods)-level+1]) + f\".{name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(absolute_import('xyz', 'nbdev', 0), 'xyz')\n",
    "test_eq(absolute_import('', 'nbdev', 1), 'nbdev')\n",
    "test_eq(absolute_import('core', 'nbdev', 1), 'nbdev.core')\n",
    "test_eq(absolute_import('core', 'nbdev/vision', 2), 'nbdev.core')\n",
    "test_eq(absolute_import('transform', 'nbdev/vision', 1), 'nbdev.vision.transform')\n",
    "test_eq(absolute_import('notebook.core', 'nbdev/data', 2), 'nbdev.notebook.core')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def update_import(source, tree, libname, f):\n",
    "    imps = L(tree).filter(risinstance(ast.ImportFrom))\n",
    "    if not imps: return\n",
    "    src = source.splitlines(True)\n",
    "    for imp in imps:\n",
    "        nmod = f(imp.module, libname, imp.level)\n",
    "        lin = imp.lineno-1\n",
    "        sec = src[lin][imp.col_offset:imp.end_col_offset]\n",
    "        newsec = re.sub(f\"(from +){'.'*imp.level}{imp.module}\", fr\"\\1{nmod}\", sec)\n",
    "        src[lin] = src[lin].replace(sec,newsec)\n",
    "    return src\n",
    "\n",
    "@patch\n",
    "def import2relative(cell:NbCell, libname):\n",
    "    if not getattr(cell,'parsed',None): return\n",
    "    src = update_import(cell.source, cell.parsed, libname, relative_import)\n",
    "    if src: cell.set_source(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = \"from nbdev.export import *\\nfrom nbdev.a.b import *\"\n",
    "cell = _make_code_cells([ss])[0]\n",
    "cell.import2relative('nbdev')\n",
    "test_eq(cell.source, 'from .export import *\\nfrom .a.b import *')\n",
    "\n",
    "cell = _make_code_cells([ss])[0]\n",
    "cell.import2relative('nbdev/a')\n",
    "test_eq(cell.source, 'from ..export import *\\nfrom .b import *')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def make(self:ModuleMaker, cells, all_cells=None):\n",
    "    \"Write module containing `cells` with `__all__` generated from `all_cells`\"\n",
    "    for cell in all_cells: cell.import2relative(Config().lib_name)\n",
    "    if not self.is_new: return self._make_exists(cells, all_cells)\n",
    "    self.fname.parent.mkdir(exist_ok=True, parents=True)\n",
    "    _all = self.make_all(all_cells)\n",
    "    trees = cells.attrgot('parsed')\n",
    "    try: last_future = max(i for i,tree in enumerate(trees) if any(\n",
    "         isinstance(t,ast.ImportFrom) and t.module=='__future__' for t in tree))+1\n",
    "    except ValueError: last_future=0\n",
    "    with self.fname.open('w') as f:\n",
    "        f.write(f\"# AUTOGENERATED! DO NOT EDIT! File to edit: {self.dest2nb}.\\n\\n\")\n",
    "        export_cells(cells[:last_future], self.hdr, f, 0)\n",
    "        f.write(create_all_cell(_all))\n",
    "        export_cells(cells[last_future:], self.hdr, f, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _print_file(fname, mx=None): print(Path(fname).read_text().strip()[:ifnone(mx,9999)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cells = _make_code_cells(\"from __future__ import print_function\", \"def a(): ...\", \"def b(): ...\")\n",
    "mm.make(cells, L([cells[1]]))\n",
    "_print_file('tmp/test/testing.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass `all_cells=None` if you don't want any `__all__` added."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def _update_all(self:ModuleMaker, all_cells, alls):\n",
    "    return pformat(alls + self.make_all(all_cells), width=160)\n",
    "\n",
    "@patch\n",
    "def _make_exists(self:ModuleMaker, cells, all_cells=None):\n",
    "    \"`make` for `is_new=False`\"\n",
    "    if all_cells: update_var('__all__', partial(self._update_all, all_cells), fn=self.fname)\n",
    "    with self.fname.open('a') as f:\n",
    "        export_cells(cells, self.hdr, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `is_new=False` then the additional definitions are added to the bottom, and any existing `__all__` is updated with the newly-added symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = _make_code_cells(\"def c(): ...\", \"def d(): ...\")\n",
    "mm = ModuleMaker(dest='tmp', name='test.testing', nb_path=Path.cwd()/'01_export.ipynb', is_new=False)\n",
    "mm.make(c2, c2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tmp.test.testing import *\n",
    "g = globals()\n",
    "for s in \"a c d\".split(): assert s in g, s\n",
    "assert 'b' not in g\n",
    "assert a() is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ExportModuleProcessor -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class ExportModuleProcessor(NotebookProcessor):\n",
    "    \"A `NotebookProcessor` which exports code to a module\"\n",
    "    def __init__(self, path, dest, mod_maker=ModuleMaker, debug=False):\n",
    "        dest = Path(dest)\n",
    "        store_attr()\n",
    "        super().__init__(path,debug=debug)\n",
    "\n",
    "    def process(self):\n",
    "        self.modules,self.in_all = defaultdict(L),defaultdict(L)\n",
    "        super().process()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify `path` containing the source notebook, `dest` where the module(s) will be exported to, and optionally a class to use to create the module (`ModuleMaker`, by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = ExportModuleProcessor(everything_fn, 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def default_exp_code(self:ExportModuleProcessor, comment, cell, exp_to): self.default_exp = exp_to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You must include a `default_exp` comment somewhere in your notebook to show what module to export to by default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.process()\n",
    "proc.default_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def exporti_code(self:ExportModuleProcessor, comment, cell, exp_to=None):\n",
    "    mod = ifnone(exp_to, '#')\n",
    "    self.modules[mod].append(cell)\n",
    "    return mod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exported cells are stored in a `dict` called `modules`, where the keys are the modules exported to. Those without an explicit module are stored in the `'#'` key, which will be exported to `default_exp`.\n",
    "\n",
    "`exporti` comments are used to export a cell, without including the definition in `__all__`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc.process()\n",
    "proc.modules['#']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def export_code(self:ExportModuleProcessor, comment, cell, exp_to=None):\n",
    "    mod = self.exporti_code(comment, cell, exp_to=exp_to)\n",
    "    self.in_all[mod].append(cell)\n",
    "ExportModuleProcessor.exports_code = ExportModuleProcessor.export_code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`export` and `exports` export a cell and include definitions in `__all__`. (`exports` also displays the source code in documentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def create_modules(self:ExportModuleProcessor):\n",
    "    self.process()\n",
    "    for mod,cells in self.modules.items():\n",
    "        all_cells = self.in_all[mod]\n",
    "        name = self.default_exp if mod=='#' else mod\n",
    "        mm = self.mod_maker(dest=self.dest, name=name, nb_path=self.path, is_new=mod=='#')\n",
    "        mm.make(cells, all_cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check we can import a test file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree('tmp')\n",
    "proc = ExportModuleProcessor('../tests/00_some.thing.ipynb', 'tmp')\n",
    "proc.create_modules()\n",
    "\n",
    "import tmp.some.thing\n",
    "reload(tmp.some.thing)\n",
    "test_eq(tmp.some.thing.__all__, ['a'])\n",
    "test_eq(tmp.some.thing.a, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also check that our 'everything' file exports correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proc = ExportModuleProcessor(everything_fn, 'tmp')\n",
    "proc.create_modules()\n",
    "\n",
    "import tmp.everything\n",
    "reload(tmp.everything)\n",
    "from tmp.everything import *\n",
    "g = globals()\n",
    "_alls = L(\"a b d e m n o p q\".split())\n",
    "for s in _alls.map(\"{}_y\"): assert s in g, s\n",
    "for s in \"c_y_nall _f_y_nall g_n h_n i_n j_n k_n l_n\".split(): assert s not in g, s\n",
    "for s in _alls.map(\"{}_y\") + [\"c_y_nall\", \"_f_y_nall\"]: assert hasattr(tmp.everything,s), s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That notebook should also export one extra function to `tmp.some.thing`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tmp.some.thing\n",
    "reload(tmp.some.thing)\n",
    "test_eq(tmp.some.thing.__all__, ['a','h_n'])\n",
    "test_eq(tmp.some.thing.h_n(), None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(path/'export.py').unlink(missing_ok=True)\n",
    "ExportModuleProcessor('01_export.ipynb', 'nbdev').create_modules()\n",
    "import nbdev.export\n",
    "reload(nbdev.export)\n",
    "assert hasattr(nbdev.export, 'ModuleMaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "def nb2dict(d, k=None):\n",
    "    \"Convert parsed notebook to `dict`\"\n",
    "    if k=='source': return d.splitlines(keepends=True)\n",
    "    if isinstance(d, (L,list)): return list(L(d).map(nb2dict))\n",
    "    if not isinstance(d, dict): return d\n",
    "    return dict(**{k:nb2dict(v,k) for k,v in d.items() if k[-1] != '_'})\n",
    "\n",
    "# This returns the exact same string as saved by Jupyter.\n",
    "\n",
    "assert minimal_txt==nb2dict(minimal)\n",
    "\n",
    "#export\n",
    "def write_nb(nb, path):\n",
    "    \"Write `nb` to `path`\"\n",
    "    nb = nb2dict(nb)\n",
    "    with io.open(path, 'w', encoding='utf-8') as f:\n",
    "        f.write(json.dumps(nb, sort_keys=True, indent=1, ensure_ascii=False))\n",
    "        f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
